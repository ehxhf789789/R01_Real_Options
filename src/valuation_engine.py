#!/usr/bin/env python3
"""
BIM Real Options Valuation Engine
7 Real Options + 3-Tier Probabilistic Valuation System
"""

import numpy as np
import pandas as pd
from typing import Dict, Tuple, List

try:
    from tier_system import Tier0Input, Tier1Derivation, Tier2Sampler
except ImportError:
    from .tier_system import Tier0Input, Tier1Derivation, Tier2Sampler


class ValuationEngine:
    """BIM Real Options Valuation Engine"""

    def __init__(self, n_simulations: int = 5000):
        self.n_simulations = n_simulations
        self.fixed_params = self._get_fixed_params()

    @staticmethod
    def _get_fixed_params() -> Dict:
        """ê³ ì • íŒŒë¼ë¯¸í„° (ëª¨ë¸ êµ¬ì¡° íŒŒë¼ë¯¸í„°)"""
        return {
            'risk_free_rate': 0.035,
            'discount_rate': 0.09,
            'time_steps': 12,

            # ì˜µì…˜ í–‰ì‚¬ íŒŒë¼ë¯¸í„°
            'follow_on_exercise_rate': 0.50,
            'capability_growth_rate': 0.10,
            'resource_utilization_premium': 0.06,
            'contract_flexibility_rate': 0.05,
            'switch_mobility_rate': 0.04,
            'stage_checkpoint_value': 0.03,

            # ì¡°ì • íŒŒë¼ë¯¸í„° (ê³¼ëŒ€í‰ê°€ ë°©ì§€ ê°•í™”)
            'interaction_discount': 0.18,      # 0.12 â†’ 0.18 (ë³µìˆ˜ ì˜µì…˜ ì¤‘ë³µ í• ì¸ ê°•í™”)
            'risk_premium_rate': 0.25,          # 0.15 â†’ 0.25 (ë³µì¡ë„Â·ë³€ë™ì„± ë¦¬ìŠ¤í¬ ê°•í™”)
            'deferral_multiplier': 0.08,        # 0.05 â†’ 0.08 (ê¸°íšŒë¹„ìš© ë°˜ì˜ ê°•í™”)

            # ROV ìƒí•œ ì œì•½ (Trigeorgis 1996)
            'rov_cap_ratio': 0.80,              # ROV â‰¤ 0.80 Ã— |NPV|
        }

    def run_valuation(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict]:
        """
        ì‹¤ë¬¼ì˜µì…˜ í‰ê°€ ì‹¤í–‰

        Args:
            df: Tier 0 ì…ë ¥ ë°ì´í„°í”„ë ˆì„ (6ê°œ ì»¬ëŸ¼)

        Returns:
            (ê²°ê³¼ ë°ì´í„°í”„ë ˆì„, ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼)
        """
        results = []

        for _, row in df.iterrows():
            # Tier 0 ì…ë ¥ ê°ì²´ ìƒì„± (10ê°œ ë³€ìˆ˜)
            tier0 = Tier0Input(
                project_id=row['project_id'],
                contract_amount=row['contract_amount'],
                infra_type=row['infra_type'],
                design_phase=row['design_phase'],
                contract_duration=row['contract_duration'],
                procurement_type=row['procurement_type'],
                client_type=row['client_type'],
                firm_size=row['firm_size'],
                bim_years=int(row['bim_years']),
                same_type_count=int(row['same_type_count']),
                current_utilization=float(row['current_utilization']),
            )

            # Tier 0 â†’ Tier 1 íŒŒìƒ
            tier1 = Tier1Derivation.derive(tier0)

            # Monte Carlo ì‹œë®¬ë ˆì´ì…˜
            mc_results = self._monte_carlo_simulation(tier0, tier1)

            # ê²°ê³¼ ì €ì¥
            results.append({
                'project_id': tier0.project_id,
                'contract_amount': tier0.contract_amount,
                'infra_type': tier0.infra_type,
                'design_phase': tier0.design_phase,
                **mc_results,
            })

        results_df = pd.DataFrame(results)

        # ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ë¯¼ê°ë„ ë¶„ì„
        sensitivity = self._sensitivity_analysis(df)

        return results_df, sensitivity

    def _monte_carlo_simulation(self, tier0: Tier0Input, tier1: Dict) -> Dict:
        """Monte Carlo ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ TPV ë¶„í¬ ì‚°ì¶œ"""

        contract = tier0.contract_amount

        # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ì €ì¥
        npv_samples = []
        tpv_samples = []
        rov_samples = {
            'follow_on': [], 'capability': [], 'resource': [],
            'abandonment': [], 'contract': [], 'switch': [], 'stage': [],
            'interaction': [], 'risk_premium': [], 'deferral': [],
        }

        for _ in range(self.n_simulations):
            # Tier 2 ìƒ˜í”Œë§
            tier2 = Tier2Sampler.sample(tier1)

            # NPV ê³„ì‚°
            npv = contract * (1 - tier2['cost_ratio'])
            npv_samples.append(npv)

            # 7ê°œ ì˜µì…˜ ê°€ì¹˜ ê³„ì‚°
            rov = self._calculate_all_options(contract, tier1, tier2)

            for key in rov_samples:
                if key in rov:
                    rov_samples[key].append(rov[key])

            # TPV ê³„ì‚°
            tpv = npv + rov['rov_net']
            tpv_samples.append(tpv)

        # í†µê³„ ê³„ì‚°
        tpv_array = np.array(tpv_samples)
        npv_array = np.array(npv_samples)

        # ì˜ì‚¬ê²°ì • í™•ë¥ 
        decision_probs = self._calculate_decision_probabilities(tpv_array, npv_array)

        # í‰ê·  ROV êµ¬ì„±
        rov_means = {f'rov_{k}': np.mean(v) for k, v in rov_samples.items() if v}

        return {
            # NPV
            'npv': np.mean(npv_array),
            'npv_std': np.std(npv_array),
            'npv_decision': 'Participate' if np.mean(npv_array) >= 0 else 'Reject',

            # ROV êµ¬ì„± (7ê°œ ì˜µì…˜)
            'rov_follow_on': np.mean(rov_samples['follow_on']),
            'rov_capability': np.mean(rov_samples['capability']),
            'rov_resource': np.mean(rov_samples['resource']),
            'rov_abandonment': np.mean(rov_samples['abandonment']),
            'rov_contract': np.mean(rov_samples['contract']),
            'rov_switch': np.mean(rov_samples['switch']),
            'rov_stage': np.mean(rov_samples['stage']),

            # ROV í•©ê³„
            'rov_gross': np.mean([sum(x) for x in zip(
                rov_samples['follow_on'], rov_samples['capability'],
                rov_samples['resource'], rov_samples['abandonment'],
                rov_samples['contract'], rov_samples['switch'], rov_samples['stage']
            )]),

            # ì¡°ì • ìš”ì†Œ
            'interaction_adjustment': np.mean(rov_samples['interaction']),
            'risk_premium': np.mean(rov_samples['risk_premium']),
            'deferral_value': np.mean(rov_samples['deferral']),

            # ROV Net
            'rov_net': np.mean([t - n for t, n in zip(tpv_samples, npv_samples)]),

            # TPV
            'tpv': np.mean(tpv_array),
            'tpv_std': np.std(tpv_array),
            'tpv_ci_lower': np.percentile(tpv_array, 5),
            'tpv_ci_upper': np.percentile(tpv_array, 95),

            # ì˜ì‚¬ê²°ì • í™•ë¥  (ì‹ ê·œ)
            **decision_probs,

            # TPV ì˜ì‚¬ê²°ì • (ìµœëŒ€ í™•ë¥  ê¸°ì¤€)
            'tpv_decision': self._get_most_likely_decision(decision_probs),

            # ì˜ì‚¬ê²°ì • ë³€ê²½
            'decision_changed': self._check_decision_change(
                np.mean(npv_array), decision_probs
            ),

            # ì˜ì‚¬ê²°ì • ë°©í–¥
            'decision_direction': self._get_decision_direction(
                np.mean(npv_array), decision_probs
            ),
        }

    def _calculate_all_options(self, contract: float, tier1: Dict, tier2: Dict) -> Dict:
        """7ê°œ ì˜µì…˜ ê°€ì¹˜ + ì¡°ì • ìš”ì†Œ ê³„ì‚°"""

        fp = self.fixed_params  # ê³ ì • íŒŒë¼ë¯¸í„°

        # === (+) ì˜µì…˜ ê°€ì¹˜ (7ê°œ) ===

        # ê²½ìŸ ë¦¬ìŠ¤í¬ í• ì¸ ê³„ìˆ˜ (Porter 1980, Li & Akintoye 2003)
        competition_discount = 1 - (tier2['competition_level'] * 0.25)

        # 1. í›„ì†ì„¤ê³„ ì°¸ì—¬ ì˜µì…˜ - ë³µí•©ì˜µì…˜ (Geske 1979) + ìŒìˆ˜ í—ˆìš©
        if tier2['has_follow_on'] and tier2['follow_on_prob'] > 0:
            # 1ë‹¨ê³„: ê¸°ë³¸ì„¤ê³„ NPV í‰ê°€
            npv_stage1 = contract * (1 - tier2['cost_ratio'])

            # 2ë‹¨ê³„: ì‹¤ì‹œì„¤ê³„ ê¸°ëŒ€ê°€ì¹˜
            S2 = contract * tier2['follow_on_multiplier'] * tier2['follow_on_prob']
            K2 = contract * tier2['follow_on_multiplier'] * tier2['cost_ratio']

            # ë³µí•©ì˜µì…˜ í–‰ì‚¬ ì¡°ê±´ (3ê°œ ëª¨ë‘ ë§Œì¡±í•´ì•¼ í–‰ì‚¬)
            condition1 = npv_stage1 > 0
            condition2 = tier2['follow_on_prob'] > 0.5
            condition3 = tier2['strategic_alignment'] > 0.4

            if condition1 and condition2 and condition3:
                # Geske ê·¼ì‚¬ì‹ (ê²½ìŸ ë¦¬ìŠ¤í¬ ë°˜ì˜)
                # ğŸ”¥ FIX: ì „ëµì  ë¶€ì í•© ì‹œ ìŒìˆ˜ ì „í™˜ í—ˆìš©
                if tier2['strategic_alignment'] < 0.50:
                    strategic_penalty = (0.50 - tier2['strategic_alignment']) * contract * 0.15
                    intrinsic_value = (S2 - K2) - strategic_penalty  # ìŒìˆ˜ ê°€ëŠ¥
                else:
                    intrinsic_value = max(S2 - K2, 0)

                time_decay = np.exp(-fp['risk_free_rate'] * tier1['time_to_decision'])

                # ì¸í”„ë¼ ìœ í˜•ë³„ ì‹¤í˜„ë¥  (ì¡°ë‹¬ì²­ 2023 ë¶„ë¦¬ë°œì£¼ìœ¨ ê¸°ë°˜)
                infra_realization = {
                    'Road': 0.25,     # ë„ë¡œ: ë¶„ë¦¬ë°œì£¼ 75% â†’ ì‹¤í˜„ 25%
                    'Bridge': 0.42,   # êµëŸ‰: ë¶„ë¦¬ë°œì£¼ 58% â†’ ì‹¤í˜„ 42%
                    'Tunnel': 0.55    # í„°ë„: ë¶„ë¦¬ë°œì£¼ 45% â†’ ì‹¤í˜„ 55%
                }
                infra_type = tier2.get('infra_type', 'Road')
                realization_rate = infra_realization.get(infra_type, 0.35)

                rov_follow = intrinsic_value * time_decay * realization_rate * competition_discount
            else:
                rov_follow = 0
        else:
            rov_follow = 0

        # 2. ì—­ëŸ‰ ì¶•ì  ì˜µì…˜ (í•œê³„íš¨ìš© ì²´ê° ë°˜ì˜ - Argote & Epple 1990) + ìŒìˆ˜ í—ˆìš©
        # ğŸ”¥ FIX: BIM ë¯¸ìˆ™ë ¨ ê¸°ì—…ì€ í•™ìŠµ ë¹„ìš© > í•™ìŠµ íš¨ê³¼ â†’ ìŒìˆ˜
        bim_threshold = 0.60
        if tier2['capability_level'] < bim_threshold:
            # ë¯¸ìˆ™ë ¨: í•™ìŠµ ë¹„ìš©ì´ í•™ìŠµ íš¨ê³¼ë¥¼ ì´ˆê³¼
            learning_cost = contract * tier2['complexity'] * (bim_threshold - tier2['capability_level']) * 0.20
            learning_benefit = contract * tier2['complexity'] * tier2['capability_level'] * 0.10
            rov_capability = learning_benefit - learning_cost  # ìŒìˆ˜ ê°€ëŠ¥
        else:
            # ìˆ™ë ¨: ê¸°ì¡´ ë¡œì§ ìœ ì§€
            learning_diminishing = 1 - (tier2['capability_level'] ** 1.5)
            rov_capability = (contract * tier2['complexity'] *
                              fp['capability_growth_rate'] * learning_diminishing)
        rov_capability *= competition_discount  # ê²½ìŸ í• ì¸

        # 3. ìì› í™œìš© ì˜µì…˜ + ìŒìˆ˜ í—ˆìš©
        # ğŸ”¥ FIX: ê°€ë™ë¥  ê³¼ë¶€í•˜ ì‹œ ê¸°íšŒë¹„ìš© > ìœ íœ´ìì› ê°€ì¹˜ â†’ ìŒìˆ˜
        if tier2['resource_utilization'] > 0.80:
            # ê°€ë™ë¥  ì´ˆê³¼: ê¸°íšŒë¹„ìš© ë°œìƒ
            overload_cost = (tier2['resource_utilization'] - 0.80) * contract * 0.15
            idle_benefit = contract * (1 - tier2['resource_utilization']) * 0.06
            rov_resource = idle_benefit - overload_cost  # ìŒìˆ˜ ê°€ëŠ¥
        else:
            # ì •ìƒ ê°€ë™ë¥ 
            resource_mult = 1 - tier2['resource_utilization']
            rov_resource = (contract * resource_mult *
                            fp['resource_utilization_premium'] * tier2['complexity'])
        rov_resource *= competition_discount  # ê²½ìŸ í• ì¸

        # 4. í¬ê¸° ì˜µì…˜ (Triantis 2005 - ì¡°ê¸° ì¢…ë£Œ ìœ ì—°ì„±) + ìŒìˆ˜ í—ˆìš©
        npv = contract * (1 - tier2['cost_ratio'])
        # ğŸ”¥ FIX: NPV > 0ì¸ ìš°ëŸ‰ í”„ë¡œì íŠ¸ëŠ” í¬ê¸° ì˜µì…˜ì´ ì˜¤íˆë ¤ ì†ì‹¤
        if npv > 0:
            # ìš°ëŸ‰ í”„ë¡œì íŠ¸: í¬ê¸°í•˜ë©´ ì†ì‹¤ â†’ ìŒìˆ˜
            rov_abandonment = -contract * 0.02
        elif npv < contract * 0.15 or tier2['strategic_alignment'] < 0.30:
            # ë¶€ì‹¤ í”„ë¡œì íŠ¸: í¬ê¸° ì˜µì…˜ ê°€ì¹˜ ìˆìŒ
            completion_ratio = 0.45  # í‰ê·  45% ìˆ˜í–‰ í›„ í¬ê¸°
            salvage = contract * completion_ratio * 0.80  # ê¸°ì„± 80% ì¸ì •

            # ìì› ì¬ë°°ì¹˜ ê°€ì¹˜
            reallocation_value = (contract * (1 - completion_ratio) *
                                  tier2['resource_utilization'] * 0.50)

            rov_abandonment = max(salvage + reallocation_value - contract * completion_ratio, 0)
        else:
            rov_abandonment = 0

        # 5. ì¶•ì†Œ ì˜µì…˜ (ì‹ ê·œ)
        scope_flex = {'Road': 0.7, 'Bridge': 0.5, 'Tunnel': 0.3}.get(
            tier2.get('infra_type', 'Road'), 0.5
        )
        adverse_prob = max(0, tier2['cost_ratio'] - 0.85) * 2
        rov_contract = contract * scope_flex * adverse_prob * fp['contract_flexibility_rate']

        # 6. ì „í™˜ ì˜µì…˜ (ì‹ ê·œ)
        resource_mobility = 1 - tier2['complexity'] * 0.5
        rov_switch = (contract * resource_mobility *
                      tier2['alternative_attractiveness'] * fp['switch_mobility_rate'])

        # 7. ë‹¨ê³„ì  íˆ¬ì ì˜µì…˜ (ì‹ ê·œ)
        info_factor = min(tier2['time_to_decision'], 2.0) / 2.0
        rov_stage = (contract * tier2['n_milestones'] *
                     info_factor * fp['stage_checkpoint_value'])

        # (+) í•©ê³„
        rov_gross = (rov_follow + rov_capability + rov_resource +
                     rov_abandonment + rov_contract + rov_switch + rov_stage)

        # === (-) ì¡°ì • ìš”ì†Œ (3ê°œ) ===

        # 1. ì˜µì…˜ ìƒí˜¸ì‘ìš© í• ì¸ (Trigeorgis 1993 - ì˜µì…˜ ê°œìˆ˜ì— ë¹„ë¡€)
        active_options = sum([
            rov_follow > 0, rov_capability > 0, rov_resource > 0,
            rov_abandonment > 0, rov_contract > 0, rov_switch > 0, rov_stage > 0
        ])
        if active_options >= 6:
            interaction_discount = 0.30
        elif active_options >= 4:
            interaction_discount = 0.22
        else:
            interaction_discount = 0.15

        interaction = rov_gross * interaction_discount
        rov_adj = rov_gross - interaction

        # 2. ë¦¬ìŠ¤í¬ í”„ë¦¬ë¯¸ì—„ (Borison 2005 - ë³€ë™ì„± ë° ë³µì¡ë„ ì—°ë™)
        base_premium = 0.15
        volatility_premium = tier2['volatility'] * 0.30
        complexity_premium = tier2['complexity'] * 0.10
        risk_premium_rate = base_premium + volatility_premium + complexity_premium
        risk_premium = rov_adj * risk_premium_rate

        # 3. ì—°ê¸°ì˜µì…˜ ê°€ì¹˜ (Dixit & Pindyck 1994 - ìì› ì œì•½ ë°˜ì˜)
        resource_opportunity = tier2['resource_utilization']  # ê°€ë™ë¥  ë†’ìœ¼ë©´ ì—°ê¸° ê°€ì¹˜ ì¦ê°€
        market_opportunity = tier2['alternative_attractiveness'] * (1 + resource_opportunity)
        deferral = (contract * (1 - tier2['strategic_alignment']) *
                    market_opportunity * 0.18 * np.sqrt(tier2['time_to_decision']))

        # ROV Net (ì¡°ì • ì „)
        rov_net_raw = rov_adj - risk_premium - deferral

        # === ROV ìƒí•œ ì œì•½ (Trigeorgis 1996) ===
        # NPV ëŒ€ë¹„ ê³¼ë„í•œ ROV ì œí•œ
        npv = contract * (1 - tier2['cost_ratio'])
        rov_cap = abs(npv) * fp['rov_cap_ratio']  # ROV â‰¤ 0.80 Ã— |NPV|

        if rov_net_raw > rov_cap:
            rov_net = rov_cap
            cap_applied = True
        else:
            rov_net = rov_net_raw
            cap_applied = False

        # ROV Net = 3ê°€ì§€ ì¡°ì •ìš”ì†Œë§Œ ì ìš© (ë…¼ë¬¸ ì •ì˜)

        return {
            'follow_on': rov_follow,
            'capability': rov_capability,
            'resource': rov_resource,
            'abandonment': rov_abandonment,
            'contract': rov_contract,
            'switch': rov_switch,
            'stage': rov_stage,
            'interaction': interaction,
            'risk_premium': risk_premium,
            'deferral': deferral,
            'rov_net': rov_net,
            'rov_cap_applied': cap_applied,  # ë””ë²„ê¹…ìš©
            'rov_cap_value': rov_cap,        # ë””ë²„ê¹…ìš©
        }

    def _calculate_decision_probabilities(self, tpv_array: np.ndarray,
                                           npv_array: np.ndarray) -> Dict:
        """ì˜ì‚¬ê²°ì • í™•ë¥  ê³„ì‚° (ë³´ì •ëœ ì„ê³„ê°’)"""
        n = len(tpv_array)
        npv_mean = np.mean(npv_array)

        # ê³„ì•½ê¸ˆì•¡ ëŒ€ë¹„ ROV ê¸°ì—¬ë„ë¡œ íŒë‹¨ (ë” ì—„ê²©í•œ ê¸°ì¤€)
        # Strong: TPVê°€ NPVì˜ 150% ì´ìƒ AND TPV > 30M
        # Participate: NPVì˜ 105-150% OR 10M < TPV <= 30M
        # Conditional: NPVì˜ 80-105% OR 0 < TPV <= 10M
        # Reject: TPV < NPVì˜ 80% OR TPV <= 0

        return {
            'prob_strong_participate': np.sum((tpv_array > npv_mean * 1.5) & (tpv_array > 30)) / n,
            'prob_participate': np.sum(((tpv_array > npv_mean * 1.05) & (tpv_array <= npv_mean * 1.5)) |
                                      ((tpv_array > 10) & (tpv_array <= 30))) / n,
            'prob_conditional': np.sum(((tpv_array > npv_mean * 0.80) & (tpv_array <= npv_mean * 1.05)) |
                                      ((tpv_array > 0) & (tpv_array <= 10))) / n,
            'prob_reject': np.sum((tpv_array <= npv_mean * 0.80) | (tpv_array <= 0)) / n,
            'decision_robustness': None,  # ì•„ë˜ì—ì„œ ê³„ì‚°
        }

    def _get_most_likely_decision(self, probs: Dict) -> str:
        """ê°€ì¥ í™•ë¥  ë†’ì€ ì˜ì‚¬ê²°ì • ë°˜í™˜"""
        decision_map = {
            'prob_strong_participate': 'Strong Participate',
            'prob_participate': 'Participate',
            'prob_conditional': 'Conditional',
            'prob_reject': 'Reject',
        }

        max_key = max(decision_map.keys(), key=lambda k: probs.get(k, 0))
        probs['decision_robustness'] = probs[max_key]

        return decision_map[max_key]

    def _check_decision_change(self, npv_mean: float, probs: Dict) -> bool:
        """ì˜ì‚¬ê²°ì • ë³€ê²½ ì—¬ë¶€ íŒì •"""
        npv_decision = 'Participate' if npv_mean >= 0 else 'Reject'

        # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ TPV ì˜ì‚¬ê²°ì •
        if probs['prob_strong_participate'] + probs['prob_participate'] > 0.5:
            tpv_direction = 'Participate'
        elif probs['prob_reject'] > 0.5:
            tpv_direction = 'Reject'
        else:
            tpv_direction = 'Conditional'

        return npv_decision != tpv_direction

    def _get_decision_direction(self, npv_mean: float, probs: Dict) -> str:
        """ì˜ì‚¬ê²°ì • ë°©í–¥ íŒë‹¨ (Up: ë¶ˆì°¸â†’ì°¸ì—¬, Down: ì°¸ì—¬â†’ë¶ˆì°¸)"""
        npv_decision = 'Participate' if npv_mean >= 0 else 'Reject'

        # TPV ê¸°ë°˜ ì˜ì‚¬ê²°ì • ë°©í–¥
        if probs['prob_strong_participate'] + probs['prob_participate'] > 0.5:
            tpv_direction = 'Participate'
        elif probs['prob_reject'] > 0.5:
            tpv_direction = 'Reject'
        else:
            return 'No Change'

        # ë°©í–¥ íŒì •
        if npv_decision == 'Reject' and tpv_direction == 'Participate':
            return 'Up'
        elif npv_decision == 'Participate' and tpv_direction == 'Reject':
            return 'Down'
        else:
            return 'No Change'

    def _sensitivity_analysis(self, df: pd.DataFrame) -> Dict:
        """ë¯¼ê°ë„ ë¶„ì„ (Tier 2 ë¶„í¬ íŒŒë¼ë¯¸í„° ë³€ë™)"""

        # ê°„ì†Œí™”ëœ ë¯¼ê°ë„ ë¶„ì„: Tier 2 íŒŒë¼ë¯¸í„°ë³„ TPV ì˜í–¥ë„
        # ì¬ê·€ í˜¸ì¶œ ë°©ì§€ë¥¼ ìœ„í•´ ê°„ë‹¨í•œ ë¶„ì„ë§Œ ìˆ˜í–‰

        sensitivity_params = [
            'cost_ratio', 'follow_on_prob', 'strategic_alignment',
            'alternative_attractiveness', 'volatility', 'capability_level',
            'resource_utilization', 'recovery_rate', 'competition_level', 'complexity'
        ]

        sensitivity_results = {}

        for param in sensitivity_params:
            # íŒŒë¼ë¯¸í„°ë³„ ì˜í–¥ë„ (í”Œë ˆì´ìŠ¤í™€ë”)
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Tier2Samplerì˜ ë¶„í¬ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ ì¬í‰ê°€
            sensitivity_results[param] = {
                'impact': np.random.uniform(-0.3, 0.3),
                'direction': 'positive' if np.random.random() > 0.5 else 'negative'
            }

        return {
            'baseline_tpv': 0.0,  # í”Œë ˆì´ìŠ¤í™€ë”
            'param_sensitivity': sensitivity_results,
            'most_sensitive_param': max(sensitivity_results.items(),
                                        key=lambda x: abs(x[1]['impact']))[0]
        }


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == '__main__':
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    sample_data = pd.DataFrame([
        {
            'project_id': 'P001',
            'contract_amount': 250,
            'infra_type': 'Road',
            'design_phase': 'ê¸°ë³¸ì„¤ê³„',
            'contract_duration': 1.0,
            'procurement_type': 'ì œí•œê²½ìŸ',
            'client_type': 'ì¤‘ì•™'
        }
    ])

    engine = ValuationEngine(n_simulations=1000)
    results, sensitivity = engine.run_valuation(sample_data)

    print("\n=== Valuation Results ===")
    print(results.to_string())
    print("\n=== Sensitivity Analysis ===")
    print(f"Baseline TPV: {sensitivity['baseline_tpv']:.2f}M")
    print(f"Most Sensitive Parameter: {sensitivity['most_sensitive_param']}")
